{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodingChallenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyODG+w9Fl7h9wGkLUjWui50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c6441df6acf46d283462d605414b23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_342604d253b34d2db92d7a32bcb541ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f0d0fcfae1a49f0bdd66697502cb443",
              "IPY_MODEL_2e0d5f627dcd45289e006cb1d9feeec4",
              "IPY_MODEL_1f1d511784f1487da569723f164a63cc"
            ]
          }
        },
        "342604d253b34d2db92d7a32bcb541ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f0d0fcfae1a49f0bdd66697502cb443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21877e719377404dbea76f132341ddbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07a1477dc12d4a34b6877c801760a49a"
          }
        },
        "2e0d5f627dcd45289e006cb1d9feeec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85a724ec7e7c4768ac1a46ea3758c3b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f996edb70c646549f96d1953bc8566d"
          }
        },
        "1f1d511784f1487da569723f164a63cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_767210ace4a348b7af50da77b81f4c33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 553/553 [00:00&lt;00:00, 21.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_951c5027fd5a417a94d74686a50c5cf4"
          }
        },
        "21877e719377404dbea76f132341ddbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07a1477dc12d4a34b6877c801760a49a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85a724ec7e7c4768ac1a46ea3758c3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f996edb70c646549f96d1953bc8566d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "767210ace4a348b7af50da77b81f4c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "951c5027fd5a417a94d74686a50c5cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b10ae47d1e04cb09b76dc1f15c886ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fadd1c2c1eee444285cc1f7d95718b4a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77ef84b4a68246f09edc41cf8396b672",
              "IPY_MODEL_f269a32c5b3d4f8aaf5d818e6d8a06fa",
              "IPY_MODEL_94b45c3088a745ec840f5f49fd13f9c4"
            ]
          }
        },
        "fadd1c2c1eee444285cc1f7d95718b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77ef84b4a68246f09edc41cf8396b672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea3ed2d7e2a2479f9e0941e61ed886e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4717176aa5b0484490bce81198a2b330"
          }
        },
        "f269a32c5b3d4f8aaf5d818e6d8a06fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05a953f30a6e4b9faa592f57bbf9cb23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1200794589,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1200794589,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6775cbbf98244d36825d2bc596526bbb"
          }
        },
        "94b45c3088a745ec840f5f49fd13f9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0104e3bfec0416c8543c7785d06c3c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:20&lt;00:00, 62.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_315028ca7ebe424ab38858b7ef754fe0"
          }
        },
        "ea3ed2d7e2a2479f9e0941e61ed886e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4717176aa5b0484490bce81198a2b330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05a953f30a6e4b9faa592f57bbf9cb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6775cbbf98244d36825d2bc596526bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0104e3bfec0416c8543c7785d06c3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "315028ca7ebe424ab38858b7ef754fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pruzhinki/JetBrains/blob/main/CodingChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cESsDOVADyrM"
      },
      "source": [
        "In this coding challenge, I was required to fine-tune and evaluate a small pre-trained model (gs://t5-data/pretrained_models/mt5/small) on a new task of predicting the language a given text is written in (e.g. using the 14 languages from XNLI dataset)\n",
        "\n",
        "This project is using the TensorFlow T5 codebase, therefore I was asked to use [t5.models.HfPyTorchModel API](https://github.com/google-research/text-to-text-transfer-transformer/blob/a08f0d1c4a7caa6495aec90ce769a29787c3c87c/t5/models/hf_model.py#L38)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kEQJjxDR0RC"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/google-research/text-to-text-transfer-transformer.git\n",
        "%cd text-to-text-transfer-transformer  \n",
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ote6sU76R8b3"
      },
      "source": [
        "import t5\n",
        "import t5.models\n",
        "import torch\n",
        "import tensorflow.compat.v1 as tf\n",
        "import transformers\n",
        "import tensorflow_datasets as tfds\n",
        "import seqio\n",
        "import functools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0HsEh0-pjhd"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPUAZK4YIOFv"
      },
      "source": [
        "#Dataset and data preprocessing\n",
        "\n",
        "I will use the [Language Identification dataset](https://huggingface.co/datasets/amazon_reviews_multi) from kaggle to fine-tune mt5 small. I have split the dataset for train(80%) and validation(20%) and uploaded them in my github. Each record in the dataset contains the text and the language label. This means that we just need to bring this dataset into the right format, and then we can already take a look at how well T5 performs on it. After that, we will finetune on this dataset to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MApFzv8EoJ4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21c8ab9-0fef-47a8-91f1-cfdd63a134f9"
      },
      "source": [
        "URL_train = 'https://raw.githubusercontent.com/pruzhinki/JetBrains/main/train_dataset.csv'\n",
        "URL_val = 'https://raw.githubusercontent.com/pruzhinki/JetBrains/main/val_dataset.csv'\n",
        "file_path_train = tf.keras.utils.get_file(origin=URL_train)\n",
        "file_path_val = tf.keras.utils.get_file(origin=URL_val)\n",
        "\n",
        "file_path = {\n",
        "    \"train\": file_path_train,\n",
        "    \"validation\": file_path_val\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/pruzhinki/JetBrains/main/train_dataset.csv\n",
            "10346496/10340734 [==============================] - 0s 0us/step\n",
            "10354688/10340734 [==============================] - 0s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/pruzhinki/JetBrains/main/val_dataset.csv\n",
            "2654208/2646095 [==============================] - 0s 0us/step\n",
            "2662400/2646095 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axCMLdoV1gkl"
      },
      "source": [
        "Define a function to load the CSV data as tf.data.Dataset in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV1wDtMZpLnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9865cf6-b4c9-434f-b5ce-bfe4fcb36dd2"
      },
      "source": [
        "def dataset_fn(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "  ds = tf.data.TextLineDataset(file_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"\", \"\"],\n",
        "                        field_delim=\",\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  # Map each tuple to a {\"sentence\": ... \"language\": ...} dict.\n",
        "  ds = ds.map(lambda *ex: dict(zip([\"sentence\", \"language\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(dataset_fn(\"validation\").take(3)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few raw validation examples...\n",
            "{'sentence': b'klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundem\\xc3\\xa4rke  aastal viidi ta surnukeha mausoleumist \\xc3\\xa4ra ja kremeeriti zl\\xc3\\xadni linn kandis aastatel \\xe2\\x80\\x93 nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel \\xe2\\x80\\x93 nime gotvald', 'language': b'Estonian'}\n",
            "{'sentence': b'sebes joseph pereira thomas  p\\xc3\\xa5 eng the jesuits and the sino-russian treaty of nerchinsk  the diary of thomas pereira bibliotheca instituti historici s i --   rome libris', 'language': b'Swedish'}\n",
            "{'sentence': b'\\xe0\\xb8\\x96\\xe0\\xb8\\x99\\xe0\\xb8\\x99\\xe0\\xb9\\x80\\xe0\\xb8\\x88\\xe0\\xb8\\xa3\\xe0\\xb8\\xb4\\xe0\\xb8\\x8d\\xe0\\xb8\\x81\\xe0\\xb8\\xa3\\xe0\\xb8\\xb8\\xe0\\xb8\\x87 \\xe0\\xb8\\xad\\xe0\\xb8\\xb1\\xe0\\xb8\\x81\\xe0\\xb8\\xa9\\xe0\\xb8\\xa3\\xe0\\xb9\\x82\\xe0\\xb8\\xa3\\xe0\\xb8\\xa1\\xe0\\xb8\\xb1\\xe0\\xb8\\x99 thanon charoen krung \\xe0\\xb9\\x80\\xe0\\xb8\\xa3\\xe0\\xb8\\xb4\\xe0\\xb9\\x88\\xe0\\xb8\\xa1\\xe0\\xb8\\x95\\xe0\\xb8\\xb1\\xe0\\xb9\\x89\\xe0\\xb8\\x87\\xe0\\xb9\\x81\\xe0\\xb8\\x95\\xe0\\xb9\\x88\\xe0\\xb8\\x96\\xe0\\xb8\\x99\\xe0\\xb8\\x99\\xe0\\xb8\\xaa\\xe0\\xb8\\x99\\xe0\\xb8\\xb2\\xe0\\xb8\\xa1\\xe0\\xb9\\x84\\xe0\\xb8\\x8a\\xe0\\xb8\\xa2\\xe0\\xb8\\x96\\xe0\\xb8\\xb6\\xe0\\xb8\\x87\\xe0\\xb9\\x81\\xe0\\xb8\\xa1\\xe0\\xb9\\x88\\xe0\\xb8\\x99\\xe0\\xb9\\x89\\xe0\\xb8\\xb3\\xe0\\xb9\\x80\\xe0\\xb8\\x88\\xe0\\xb9\\x89\\xe0\\xb8\\xb2\\xe0\\xb8\\x9e\\xe0\\xb8\\xa3\\xe0\\xb8\\xb0\\xe0\\xb8\\xa2\\xe0\\xb8\\xb2\\xe0\\xb8\\x97\\xe0\\xb8\\xb5\\xe0\\xb9\\x88\\xe0\\xb8\\x96\\xe0\\xb8\\x99\\xe0\\xb8\\x99\\xe0\\xb8\\x95\\xe0\\xb8\\x81 \\xe0\\xb8\\x81\\xe0\\xb8\\xa3\\xe0\\xb8\\xb8\\xe0\\xb8\\x87\\xe0\\xb9\\x80\\xe0\\xb8\\x97\\xe0\\xb8\\x9e\\xe0\\xb8\\xa1\\xe0\\xb8\\xab\\xe0\\xb8\\xb2\\xe0\\xb8\\x99\\xe0\\xb8\\x84\\xe0\\xb8\\xa3 \\xe0\\xb9\\x80\\xe0\\xb8\\x9b\\xe0\\xb9\\x87\\xe0\\xb8\\x99\\xe0\\xb8\\x96\\xe0\\xb8\\x99\\xe0\\xb8\\x99\\xe0\\xb8\\xa3\\xe0\\xb8\\xb8\\xe0\\xb9\\x88\\xe0\\xb8\\x99\\xe0\\xb9\\x81\\xe0\\xb8\\xa3\\xe0\\xb8\\x81\\xe0\\xb8\\x97\\xe0\\xb8\\xb5\\xe0\\xb9\\x88\\xe0\\xb9\\x83\\xe0\\xb8\\x8a\\xe0\\xb9\\x89\\xe0\\xb9\\x80\\xe0\\xb8\\x97\\xe0\\xb8\\x84\\xe0\\xb8\\x99\\xe0\\xb8\\xb4\\xe0\\xb8\\x84\\xe0\\xb8\\x81\\xe0\\xb8\\xb2\\xe0\\xb8\\xa3\\xe0\\xb8\\xaa\\xe0\\xb8\\xa3\\xe0\\xb9\\x89\\xe0\\xb8\\xb2\\xe0\\xb8\\x87\\xe0\\xb9\\x81\\xe0\\xb8\\x9a\\xe0\\xb8\\x9a\\xe0\\xb8\\x95\\xe0\\xb8\\xb0\\xe0\\xb8\\xa7\\xe0\\xb8\\xb1\\xe0\\xb8\\x99\\xe0\\xb8\\x95\\xe0\\xb8\\x81 \\xe0\\xb8\\x9b\\xe0\\xb8\\xb1\\xe0\\xb8\\x88\\xe0\\xb8\\x88\\xe0\\xb8\\xb8\\xe0\\xb8\\x9a\\xe0\\xb8\\xb1\\xe0\\xb8\\x99\\xe0\\xb8\\x9c\\xe0\\xb9\\x88\\xe0\\xb8\\xb2\\xe0\\xb8\\x99\\xe0\\xb8\\x9e\\xe0\\xb8\\xb7\\xe0\\xb9\\x89\\xe0\\xb8\\x99\\xe0\\xb8\\x97\\xe0\\xb8\\xb5\\xe0\\xb9\\x88\\xe0\\xb9\\x80\\xe0\\xb8\\x82\\xe0\\xb8\\x95\\xe0\\xb8\\x9e\\xe0\\xb8\\xa3\\xe0\\xb8\\xb0\\xe0\\xb8\\x99\\xe0\\xb8\\x84\\xe0\\xb8\\xa3 \\xe0\\xb9\\x80\\xe0\\xb8\\x82\\xe0\\xb8\\x95\\xe0\\xb8\\x9b\\xe0\\xb9\\x89\\xe0\\xb8\\xad\\xe0\\xb8\\xa1\\xe0\\xb8\\x9b\\xe0\\xb8\\xa3\\xe0\\xb8\\xb2\\xe0\\xb8\\x9a\\xe0\\xb8\\xa8\\xe0\\xb8\\xb1\\xe0\\xb8\\x95\\xe0\\xb8\\xa3\\xe0\\xb8\\xb9\\xe0\\xb8\\x9e\\xe0\\xb9\\x88\\xe0\\xb8\\xb2\\xe0\\xb8\\xa2 \\xe0\\xb9\\x80\\xe0\\xb8\\x82\\xe0\\xb8\\x95\\xe0\\xb8\\xaa\\xe0\\xb8\\xb1\\xe0\\xb8\\xa1\\xe0\\xb8\\x9e\\xe0\\xb8\\xb1\\xe0\\xb8\\x99\\xe0\\xb8\\x98\\xe0\\xb8\\xa7\\xe0\\xb8\\x87\\xe0\\xb8\\xa8\\xe0\\xb9\\x8c \\xe0\\xb9\\x80\\xe0\\xb8\\x82\\xe0\\xb8\\x95\\xe0\\xb8\\x9a\\xe0\\xb8\\xb2\\xe0\\xb8\\x87\\xe0\\xb8\\xa3\\xe0\\xb8\\xb1\\xe0\\xb8\\x81 \\xe0\\xb9\\x80\\xe0\\xb8\\x82\\xe0\\xb8\\x95\\xe0\\xb8\\xaa\\xe0\\xb8\\xb2\\xe0\\xb8\\x97\\xe0\\xb8\\xa3 \\xe0\\xb9\\x81\\xe0\\xb8\\xa5\\xe0\\xb8\\xb0\\xe0\\xb9\\x80\\xe0\\xb8\\x82\\xe0\\xb8\\x95\\xe0\\xb8\\x9a\\xe0\\xb8\\xb2\\xe0\\xb8\\x87\\xe0\\xb8\\x84\\xe0\\xb8\\xad\\xe0\\xb9\\x81\\xe0\\xb8\\xab\\xe0\\xb8\\xa5\\xe0\\xb8\\xa1', 'language': b'Thai'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRbWih-S2ImO"
      },
      "source": [
        "Now, we write a preprocess function to convert the examples in the tf.data.Dataset into a text-to-text format, with both inputs and targets fields. Finally, we prepend 'language prediction:' to the inputs so that the model knows what task it's trying to solve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFXF7-62ucBQ"
      },
      "source": [
        "def dataset_preprocessor(ds):\n",
        "    def to_inputs_and_targets(ex):\n",
        "      \"\"\"Map {\"sentence\": ..., \"language\": ...}->{\"inputs\": ..., \"targets\": ...}.\"\"\"\n",
        "      return {'inputs': tf.strings.join(\n",
        "                  ['language prediction: ', ex['sentence']]),\n",
        "              'targets': ex['language']\n",
        "              }\n",
        "    return ds.map(to_inputs_and_targets, \n",
        "                  num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh1j1PTp2Wlo"
      },
      "source": [
        "# Creating new task\n",
        "\n",
        "T5 uses seqio for managing data pipelines and evaluaton metics. Two core components of the seqio are Task and Mixture objects.\n",
        "\n",
        "A Task is a dataset along with preprocessing functions and evaluation metrics. A Mixture is a collection of Task objects along with a mixing rate or a function defining how to compute a mixing rate based on the properties of the constituent Tasks.\n",
        "\n",
        "For this example, we will fine-tune the model to do language prediction, so we only create a new task called 'language_prediction' and put in it the registry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYThA1XouwrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b88b167-a67c-4a0a-bfee-8e51ec6eb843"
      },
      "source": [
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\":\n",
        "        seqio.Feature(\n",
        "            vocabulary=t5.data.get_default_vocabulary(), add_eos=True),\n",
        "    \"targets\":\n",
        "        seqio.Feature(\n",
        "            vocabulary=t5.data.get_default_vocabulary(), add_eos=True)\n",
        "}\n",
        "\n",
        "\n",
        "seqio.TaskRegistry.add(\n",
        "    \"language_prediction\",\n",
        "    # Specify the task source.\n",
        "    source=seqio.FunctionDataSource(\n",
        "        # Supply a function which returns a tf.data.Dataset.\n",
        "        dataset_fn=dataset_fn,\n",
        "        splits=[\"train\", \"validation\"],\n",
        "         ),\n",
        "    # Supply a list of functions that preprocess the input tf.data.Dataset.\n",
        "    preprocessors=[\n",
        "        dataset_preprocessor,\n",
        "        seqio.preprocessors.tokenize_and_append_eos\n",
        "    ],\n",
        "    # We'll use accuracy as our evaluation metric.\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    output_features=DEFAULT_OUTPUT_FEATURES,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seqio.dataset_providers.Task at 0x7f8241a32d90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idR4G-EE2tUy"
      },
      "source": [
        "Now the new task is stored in the registry. Let's look at a few pre-processed examples from the validation set. Note they contain both the tokenized (integer) and plain-text inputs and targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tovsUNup2ovT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985326bf-684c-42fb-bfd0-763d66b68ef2"
      },
      "source": [
        "nq_task = seqio.TaskRegistry.get(\"language_prediction\")\n",
        "ds = nq_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 32, \"targets\": 6})\n",
        "print(\"A few preprocessed validation examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few preprocessed validation examples...\n",
            "{'inputs_pretokenized': b'language prediction: toplumun b\\xc3\\xbcy\\xc3\\xbck bir k\\xc4\\xb1sm\\xc4\\xb1 okuma yazma bilmedi\\xc4\\x9fi i\\xc3\\xa7in molla nasredin dergisi yazarlar\\xc4\\xb1 edebi dilin geli\\xc5\\x9ftirilmesinde halk diline y\\xc3\\xb6nelme gere\\xc4\\x9fini savunmu\\xc5\\x9flard\\xc4\\xb1r dergi \\xc3\\xbclkenin gelece\\xc4\\x9fi a\\xc3\\xa7\\xc4\\xb1s\\xc4\\xb1ndan molla nasreddin ile pek \\xc3\\xa7ok konuda ama\\xc3\\xa7 birli\\xc4\\x9fi i\\xc3\\xa7erisinde olan f\\xc3\\xbcy\\xc3\\xbbzat ile dil meselesinde ayr\\xc4\\xb1lm\\xc4\\xb1\\xc5\\x9ft\\xc4\\xb1r f\\xc3\\xbcy\\xc3\\xbbzat arap\\xc3\\xa7a- fars\\xc3\\xa7a tamlamalarla ve zaman zaman a\\xc4\\x9fdal\\xc4\\xb1 bir osmanl\\xc4\\xb1 \\xc3\\xbcslubuyla se\\xc3\\xa7kin bir kesime hitap ederken molla nasreddin tamamen a\\xc3\\xa7\\xc4\\xb1k duru bir azerbaycan t\\xc3\\xbcrk\\xc3\\xa7esiyle ve sade bir \\xc3\\xbcslupla topluma y\\xc3\\xb6nelik yay\\xc4\\xb1n yapm\\xc4\\xb1\\xc5\\x9ft\\xc4\\xb1r', 'inputs': array([ 1612, 21332,    10,   420,  5171,   202,     3, 15483,    63,\n",
            "        1272,   157,     3,  8781,     3,   157,     2,     7,    51,\n",
            "           2,     3,  1825,   440,     9,     3,    63,     9,   172,\n",
            "          51,     9,     3,  3727,  5700], dtype=int32), 'targets_pretokenized': b'Turkish', 'targets': array([15423,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'language prediction: seg\\xc3\\xban el censo de []\\xe2\\x80\\x8b hab\\xc3\\xada  personas residiendo en el municipio de homer la densidad de poblaci\\xc3\\xb3n era de  habkm\\xc2\\xb2 de los  habitantes el municipio de homer estaba compuesto por el   blancos el   eran afroamericanos el   eran de otras razas y el   eran de una mezcla de razas del total de la poblaci\\xc3\\xb3n el   eran hispanos o latinos de cualquier raza[]\\xe2\\x80\\x8b', 'inputs': array([ 1612, 21332,    10,   142,   122,     2,    29,     3,    15,\n",
            "          40,   197,    29,     7,    32,    20,   784,   908,  9809,\n",
            "           2,     9,   568,     9,     7,     3,    60,     7,    23,\n",
            "        2498,   727,    32,     3,    35], dtype=int32), 'targets_pretokenized': b'Spanish', 'targets': array([5093,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'language prediction: reynolds was born in wiesbaden germany where his father a career military man was stationed he says he hails from nowhere because the family moved so often his family lived many places including germany a farm in indiana an army base in alaska kansas and missouri where he lived longer than any other place until he was old enough to move away as an adult both parents were extremely devout christians and he says he grew up with christian music all around him however his older sister owned some albums from the beatles which he says even as a very young child he loved instantly playing air guitar to their music', 'inputs': array([ 1612, 21332,    10,     3,    60,    63,    29,  1490,     7,\n",
            "          47,  2170,    16,   587,     7,  5514,    35, 13692,    63,\n",
            "         213,   112,  2353,     3,     9,  1415,  2716,   388,    47,\n",
            "        2478,    15,    26,     3,    88], dtype=int32), 'targets_pretokenized': b'English', 'targets': array([1566,    1], dtype=int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOlrD86FEJww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "6c6441df6acf46d283462d605414b23b",
            "342604d253b34d2db92d7a32bcb541ae",
            "6f0d0fcfae1a49f0bdd66697502cb443",
            "2e0d5f627dcd45289e006cb1d9feeec4",
            "1f1d511784f1487da569723f164a63cc",
            "21877e719377404dbea76f132341ddbd",
            "07a1477dc12d4a34b6877c801760a49a",
            "85a724ec7e7c4768ac1a46ea3758c3b0",
            "6f996edb70c646549f96d1953bc8566d",
            "767210ace4a348b7af50da77b81f4c33",
            "951c5027fd5a417a94d74686a50c5cf4",
            "0b10ae47d1e04cb09b76dc1f15c886ac",
            "fadd1c2c1eee444285cc1f7d95718b4a",
            "77ef84b4a68246f09edc41cf8396b672",
            "f269a32c5b3d4f8aaf5d818e6d8a06fa",
            "94b45c3088a745ec840f5f49fd13f9c4",
            "ea3ed2d7e2a2479f9e0941e61ed886e6",
            "4717176aa5b0484490bce81198a2b330",
            "05a953f30a6e4b9faa592f57bbf9cb23",
            "6775cbbf98244d36825d2bc596526bbb",
            "f0104e3bfec0416c8543c7785d06c3c3",
            "315028ca7ebe424ab38858b7ef754fe0"
          ]
        },
        "outputId": "14a372a7-6e43-4985-87c0-67b4fab03809"
      },
      "source": [
        "model = t5.models.HfPyTorchModel('google/mt5-small', \"./hft5/\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c6441df6acf46d283462d605414b23b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/553 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b10ae47d1e04cb09b76dc1f15c886ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-7wKgavSG1I"
      },
      "source": [
        "Mt5 will not generate any meaningful result for this task before fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8doFc7qO-CUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c5beb5-7441-43b6-cf11-de238fcd7b01"
      },
      "source": [
        "inputs = [\"language prediction: This is a book.\",\n",
        "          \"language prediction: Das ist ein Buch.\" ,\n",
        "          \"language prediction: 这是一本书。\"\n",
        "          ]\n",
        "model.predict(\n",
        "    inputs,\n",
        "    sequence_length={\"inputs\": 32},\n",
        "    batch_size=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:language prediction: This is a book.\n",
            "  ->  ⁇  est game here  language est prediction şihinhin     B est  \n",
            "INFO:absl:language prediction: Das ist ein Buch.\n",
            "  ->  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n",
            "INFO:absl:language prediction: 这是一本书。\n",
            "  ->  ⁇  ⁇  ⁇  ⁇ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiVN299MykN1"
      },
      "source": [
        "Evaluate the pre-trained checkpoint, before further fine-tuning. The accuracy is 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7BwxQadGVN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a889d4c6-feff-4521-8d98-93a2277e7e33"
      },
      "source": [
        "model.eval(\n",
        "    \"language_prediction\",\n",
        "    sequence_length={\"inputs\": 32, \"targets\": 6},\n",
        "    batch_size=256,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Adding task 'language_prediction' with predict metric_fn(s).\n",
            "WARNING:absl:Given sequence lengths are insufficient for some evaluation inputs or targets. These sequences will be truncated to fit, likely leading to sub-optimal results. Consider passing `None` for sequence_length to have them be automatically computed.\n",
            " Got: {'inputs': 32, 'targets': 6}, \n",
            " Max Lengths:{'inputs': 925, 'targets': 5}\n",
            "INFO:absl:Evaluating checkpoint step: 0\n",
            "INFO:absl:eval/language_prediction/accuracy at step 0: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ne6t3tx3A7e"
      },
      "source": [
        "Run 30000 steps of fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE6FsaSiBeG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17d8ba8-2808-489a-efa4-8320c328b680"
      },
      "source": [
        "model.train(\n",
        "    mixture_or_task_name='language_prediction',\n",
        "    steps=30000,\n",
        "    save_steps=3000,\n",
        "    sequence_length={\"inputs\": 32, \"targets\": 6},\n",
        "    split=\"train\",\n",
        "    batch_size=200,\n",
        "    optimizer=functools.partial(transformers.AdamW, lr=1e-4),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Saving checkpoint for step 0\n",
            "INFO:absl:Saving checkpoint for step 3000\n",
            "INFO:absl:Saving checkpoint for step 6000\n",
            "INFO:absl:Saving checkpoint for step 9000\n",
            "INFO:absl:Saving checkpoint for step 12000\n",
            "INFO:absl:Saving checkpoint for step 15000\n",
            "INFO:absl:Saving checkpoint for step 18000\n",
            "INFO:absl:Saving checkpoint for step 21000\n",
            "INFO:absl:Saving checkpoint for step 24000\n",
            "INFO:absl:Saving checkpoint for step 27000\n",
            "INFO:absl:Saving final checkpoint for step 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUrEAU9b3Frl"
      },
      "source": [
        "Evaluate after fine-tuning, the accurary is improved to 69%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqGI_7XrByEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f600e5-097f-403d-bc30-e546c675f21d"
      },
      "source": [
        "model.eval(\n",
        "    'language_prediction',\n",
        "    checkpoint_steps=\"all\",\n",
        "    sequence_length={\"inputs\": 32, \"targets\": 6},\n",
        "    batch_size=256,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Adding task 'language_prediction' with predict metric_fn(s).\n",
            "WARNING:absl:Given sequence lengths are insufficient for some evaluation inputs or targets. These sequences will be truncated to fit, likely leading to sub-optimal results. Consider passing `None` for sequence_length to have them be automatically computed.\n",
            " Got: {'inputs': 32, 'targets': 6}, \n",
            " Max Lengths:{'inputs': 925, 'targets': 5}\n",
            "INFO:absl:Evaluating checkpoint step: 0\n",
            "INFO:absl:Loading from ./hft5/model-0.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 0: 0.000\n",
            "INFO:absl:Evaluating checkpoint step: 3000\n",
            "INFO:absl:Loading from ./hft5/model-3000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 3000: 21.750\n",
            "INFO:absl:Evaluating checkpoint step: 6000\n",
            "INFO:absl:Loading from ./hft5/model-6000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 6000: 35.023\n",
            "INFO:absl:Evaluating checkpoint step: 9000\n",
            "INFO:absl:Loading from ./hft5/model-9000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 9000: 57.773\n",
            "INFO:absl:Evaluating checkpoint step: 12000\n",
            "INFO:absl:Loading from ./hft5/model-12000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 12000: 65.750\n",
            "INFO:absl:Evaluating checkpoint step: 15000\n",
            "INFO:absl:Loading from ./hft5/model-15000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 15000: 67.432\n",
            "INFO:absl:Evaluating checkpoint step: 18000\n",
            "INFO:absl:Loading from ./hft5/model-18000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 18000: 69.614\n",
            "INFO:absl:Evaluating checkpoint step: 21000\n",
            "INFO:absl:Loading from ./hft5/model-21000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 21000: 68.909\n",
            "INFO:absl:Evaluating checkpoint step: 24000\n",
            "INFO:absl:Loading from ./hft5/model-24000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 24000: 69.386\n",
            "INFO:absl:Evaluating checkpoint step: 27000\n",
            "INFO:absl:Loading from ./hft5/model-27000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 27000: 69.909\n",
            "INFO:absl:Evaluating checkpoint step: 30000\n",
            "INFO:absl:Loading from ./hft5/model-30000.checkpoint\n",
            "INFO:absl:eval/language_prediction/accuracy at step 30000: 69.909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbIteEBM3KsO"
      },
      "source": [
        "We can see that although our fine-tuned mt5 cannot always corretly recognize the language such as german, but it is able to generate a very close answer. For English and Chinese, our model has correct prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYQi9opbB8c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5bb4fe-de70-4410-d1a5-678963cb054e"
      },
      "source": [
        "inputs = [\"language prediction: How are the young Germans doing? What does the pandemic mean for them? And are there really many of them in Germany? The phenomenon in numbers.\",\n",
        "          \"language prediction: Wer schon sehr gut Deutsch spricht und in Deutschland studieren möchte, kann sich zum TestDaF anmelden.\",\n",
        "          \"language prediction: 如果你的德语已经说得很好，并且想在德国学习，你可以报名参加TestDaF。\"\n",
        "          ]\n",
        "model.predict(\n",
        "    inputs,\n",
        "    sequence_length={\"inputs\": 32},\n",
        "    batch_size=2\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:language prediction: How are the young Germans doing? What does the pandemic mean for them? And are there really many of them in Germany? The phenomenon in numbers.\n",
            "  -> English\n",
            "INFO:absl:language prediction: Wer schon sehr gut Deutsch spricht und in Deutschland studieren möchte, kann sich zum TestDaF anmelden.\n",
            "  -> English\n",
            "INFO:absl:language prediction: 如果你的德语已经说得很好，并且想在德国学习，你可以报名参加TestDaF。\n",
            "  -> Chinese\n"
          ]
        }
      ]
    }
  ]
}